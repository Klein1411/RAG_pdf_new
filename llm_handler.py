# llm_handler.py

import time
import requests
import json

from gemini_client import configure_gemini
from config import OLLAMA_API_URL, OLLAMA_MODELS

# --- C·∫§U H√åNH ---
MAX_RETRIES = 3
RETRY_DELAY = 2 # Gi√¢y

# --- C√ÅC H√ÄM G·ªåI MODEL (C√ì X·ª¨ L√ù L·ªñI) ---

def call_ollama(prompt: str, model_name: str) -> str:
    """
    G·ª≠i y√™u c·∫ßu ƒë·∫øn Ollama local API. N√©m ra Exception n·∫øu c√≥ l·ªói.
    """
    print(f"   -> üí¨ ƒêang g·ª≠i y√™u c·∫ßu ƒë·∫øn model local '{model_name}' qua Ollama...")
    payload = {
        "model": model_name,
        "prompt": prompt,
        "stream": False
    }
    try:
        response = requests.post(OLLAMA_API_URL, json=payload, timeout=120)
        response.raise_for_status()
        response_data = response.json()
        return response_data.get("response", "").strip()
    except requests.exceptions.ConnectionError as e:
        raise ConnectionError(f"Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn Ollama t·∫°i {OLLAMA_API_URL}. B·∫°n ƒë√£ b·∫≠t Ollama ch∆∞a?") from e
    except requests.exceptions.RequestException as e:
        # B·∫Øt l·ªói 404 v√† cung c·∫•p th√¥ng b√°o c·ª• th·ªÉ h∆°n
        if e.response and e.response.status_code == 404:
            raise FileNotFoundError(f"L·ªói 404: Endpoint '{OLLAMA_API_URL}' kh√¥ng t·ªìn t·∫°i. URL trong config.py c√≥ th·ªÉ sai.") from e
        raise IOError(f"L·ªói khi g·ªçi Ollama API: {e}") from e

def call_gemini(prompt: str, model) -> str:
    """
    G·ª≠i y√™u c·∫ßu ƒë·∫øn Gemini API. N√©m ra Exception n·∫øu c√≥ l·ªói.
    """
    if not model:
        raise ValueError("Model Gemini ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh.")
    print("   -> üí¨ ƒêang g·ª≠i y√™u c·∫ßu ƒë·∫øn Gemini...")
    try:
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        raise IOError(f"L·ªói khi g·ªçi Gemini API: {e}") from e

# --- H√ÄM LOGIC CH√çNH (RETRY & FALLBACK) ---

def generate_answer_with_fallback(prompt, model_choice, gemini_model, ollama_model_name):
    """
    H√†m ch√≠nh ƒë·ªÉ sinh c√¢u tr·∫£ l·ªùi, bao g·ªìm logic retry v√† fallback.
    """
    primary_func, primary_name, fallback_func, fallback_name = (None, None, None, None)

    if model_choice == '1':
        primary_func = lambda: call_gemini(prompt, gemini_model)
        primary_name = "Gemini"
        fallback_func = lambda: call_ollama(prompt, ollama_model_name)
        fallback_name = "Ollama"
    else:
        primary_func = lambda: call_ollama(prompt, ollama_model_name)
        primary_name = "Ollama"
        fallback_func = lambda: call_gemini(prompt, gemini_model)
        fallback_name = "Gemini"

    # --- Th·ª≠ model ch√≠nh ---
    print(f"\n‚ñ∂Ô∏è ƒêang th·ª≠ model ch√≠nh: {primary_name}...")
    for attempt in range(MAX_RETRIES):
        try:
            answer = primary_func()
            return answer # Tr·∫£ v·ªÅ n·∫øu th√†nh c√¥ng
        except Exception as e:
            print(f"   -> ‚ö†Ô∏è L·∫ßn th·ª≠ {attempt + 1}/{MAX_RETRIES} v·ªõi {primary_name} th·∫•t b·∫°i: {e}")
            if attempt < MAX_RETRIES - 1:
                time.sleep(RETRY_DELAY)
            else:
                print(f"   -> ‚ùå {primary_name} th·∫•t b·∫°i ho√†n to√†n.")

    # --- Th·ª≠ model d·ª± ph√≤ng ---
    print(f"\n‚Ü™Ô∏è Chuy·ªÉn sang model d·ª± ph√≤ng: {fallback_name}...")
    for attempt in range(MAX_RETRIES):
        try:
            answer = fallback_func()
            return answer # Tr·∫£ v·ªÅ n·∫øu th√†nh c√¥ng
        except Exception as e:
            print(f"   -> ‚ö†Ô∏è L·∫ßn th·ª≠ {attempt + 1}/{MAX_RETRIES} v·ªõi {fallback_name} th·∫•t b·∫°i: {e}")
            if attempt < MAX_RETRIES - 1:
                time.sleep(RETRY_DELAY)
            else:
                print(f"   -> ‚ùå {fallback_name} c≈©ng th·∫•t b·∫°i.")

    return "[L·ªñI H·ªÜ TH·ªêNG] C·∫£ hai model ch√≠nh v√† d·ª± ph√≤ng ƒë·ªÅu kh√¥ng th·ªÉ ph·∫£n h·ªìi."


# --- H√ÄM KH·ªûI T·∫†O V√Ä L·ª∞A CH·ªåN ---

def initialize_and_select_llm():
    """
    X·ª≠ l√Ω vi·ªác c·∫•u h√¨nh v√† l·ª±a ch·ªçn model c·ªßa ng∆∞·ªùi d√πng.
    Tr·∫£ v·ªÅ: (model_choice, gemini_model, ollama_model_name)
    """
    print("\n‚ú® ƒêang c·∫•u h√¨nh c√°c model sinh c√¢u tr·∫£ l·ªùi...")
    gemini_model = configure_gemini()
    if gemini_model:
        print("   -> ‚úÖ Gemini ƒë√£ s·∫µn s√†ng.")
    else:
        print("   -> ‚ö†Ô∏è Kh√¥ng th·ªÉ c·∫•u h√¨nh Gemini. N√≥ s·∫Ω kh√¥ng kh·∫£ d·ª•ng.")

    ollama_model_name = ""
    model_choice = ""
    
    while True:
        print("\nVui l√≤ng ch·ªçn model CH√çNH ƒë·ªÉ sinh c√¢u tr·∫£ l·ªùi:")
        prompt_text = "   1: Gemini (Cloud API)\n   2: Ollama (Local)\nL·ª±a ch·ªçn c·ªßa b·∫°n: "
        model_choice = input(prompt_text).strip()
        
        if model_choice == '1':
            if gemini_model:
                print("   -> ‚úÖ Model ch√≠nh l√† Gemini.")
                return model_choice, gemini_model, ollama_model_name
            else:
                print("   -> ‚ùå Gemini ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh, vui l√≤ng ch·ªçn Ollama.")
        elif model_choice == '2':
            if not OLLAMA_MODELS:
                print("   -> ‚ùå Danh s√°ch model Ollama trong config.py ƒëang tr·ªëng.")
                continue

            print("   -> Vui l√≤ng ch·ªçn model Ollama:")
            for i, model in enumerate(OLLAMA_MODELS):
                default_text = " (m·∫∑c ƒë·ªãnh)" if i == 0 else ""
                print(f"      {i+1}: {model}{default_text}")

            while True:
                choice = input(f"   -> L·ª±a ch·ªçn c·ªßa b·∫°n (nh·∫•n Enter ƒë·ªÉ ch·ªçn m·∫∑c ƒë·ªãnh): ").strip()
                if not choice:
                    ollama_model_name = OLLAMA_MODELS[0]
                    break
                try:
                    choice_idx = int(choice) - 1
                    if 0 <= choice_idx < len(OLLAMA_MODELS):
                        ollama_model_name = OLLAMA_MODELS[choice_idx]
                        break
                    else:
                        print("      -> L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá.")
                except ValueError:
                    print("      -> Vui l√≤ng nh·∫≠p m·ªôt s·ªë.")
            
            print(f"   -> ‚úÖ Model ch√≠nh l√† '{ollama_model_name}' t·ª´ Ollama.")
            return model_choice, gemini_model, ollama_model_name
        else:
            print("   -> L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá. Vui l√≤ng nh·∫≠p 1 ho·∫∑c 2.")
