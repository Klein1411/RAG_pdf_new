import os
import logging
from typing import Union, List, Optional
import dotenv
import google.generativeai as genai
from google.generativeai.types import GenerateContentResponse

# C·∫•u h√¨nh logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class GeminiClient:
    """
    M·ªôt tr√¨nh qu·∫£n l√Ω stateful cho API c·ªßa Google Gemini v·ªõi h·ªó tr·ª£ fallback model.

    Class n√†y s·∫Ω qu·∫£n l√Ω:
    1. Danh s√°ch c√°c API key v√† t·ª± ƒë·ªông xoay v√≤ng qua c√°c key khi g·∫∑p l·ªói quota
    2. Danh s√°ch c√°c model v√† t·ª± ƒë·ªông fallback khi model ch√≠nh th·∫•t b·∫°i
    
    Attributes:
        api_keys: Danh s√°ch c√°c API key ƒë∆∞·ª£c load t·ª´ .env
        current_key_index: Index c·ªßa key hi·ªán t·∫°i ƒëang ƒë∆∞·ª£c s·ª≠ d·ª•ng
        model_names: Danh s√°ch c√°c model theo th·ª© t·ª± ∆∞u ti√™n
        current_model_index: Index c·ªßa model hi·ªán t·∫°i ƒëang ƒë∆∞·ª£c s·ª≠ d·ª•ng
        model: Instance c·ªßa GenerativeModel
    """
    def __init__(self, model_names: Optional[List[str]] = None) -> None:
        dotenv.load_dotenv()
        self.api_keys: List[str] = [key for key in [os.getenv(f"GEMINI_API_KEY_{i}") for i in range(1, 10)] if key]
        if not self.api_keys:
            logger.error("Kh√¥ng t√¨m th·∫•y bi·∫øn m√¥i tr∆∞·ªùng GEMINI_API_KEY n√†o trong file .env")
            raise ValueError("Kh√¥ng t√¨m th·∫•y bi·∫øn m√¥i tr∆∞·ªùng GEMINI_API_KEY n√†o trong file .env")

        # N·∫øu kh√¥ng truy·ªÅn model_names, s·ª≠ d·ª•ng t·ª´ config
        if model_names is None:
            try:
                from src.config import GEMINI_MODELS
                self.model_names: List[str] = GEMINI_MODELS
            except ImportError:
                # Fallback n·∫øu kh√¥ng import ƒë∆∞·ª£c config
                self.model_names: List[str] = ["gemini-2.5-flash", "gemini-2.0-flash-exp", "gemini-1.5-flash", "gemini-1.5-flash-8b"]
        else:
            self.model_names: List[str] = model_names

        self.current_key_index: int = 0
        self.current_model_index: int = 0
        self.model: Optional[genai.GenerativeModel] = None
        self._configure_client()
        logger.info(f"‚úÖ GeminiClient ƒë√£ kh·ªüi t·∫°o v·ªõi {len(self.api_keys)} API key(s) v√† {len(self.model_names)} model(s)")

    def _configure_client(self) -> bool:
        """
        C·∫•u h√¨nh client genai v·ªõi key v√† model hi·ªán t·∫°i.
        
        Returns:
            True n·∫øu c·∫•u h√¨nh th√†nh c√¥ng, False n·∫øu ƒë√£ h·∫øt key
        """
        if self.current_key_index >= len(self.api_keys):
            logger.warning("ƒê√£ h·∫øt key ƒë·ªÉ th·ª≠")
            return False
        
        if self.current_model_index >= len(self.model_names):
            logger.warning("ƒê√£ h·∫øt model ƒë·ªÉ th·ª≠")
            return False
        
        current_key = self.api_keys[self.current_key_index]
        current_model = self.model_names[self.current_model_index]
        logger.info(f"üîë ƒêang c·∫•u h√¨nh Gemini v·ªõi API Key #{self.current_key_index + 1}, Model: {current_model}")
        genai.configure(api_key=current_key)
        self.model = genai.GenerativeModel(current_model)
        return True

    def _switch_to_next_key(self) -> bool:
        """
        Chuy·ªÉn sang API key ti·∫øp theo v√† c·∫•u h√¨nh l·∫°i client.
        
        Returns:
            True n·∫øu chuy·ªÉn th√†nh c√¥ng, False n·∫øu ƒë√£ h·∫øt key
        """
        self.current_key_index += 1
        if self.current_key_index < len(self.api_keys):
            logger.info(f"üîÑ Chuy·ªÉn sang API Key #{self.current_key_index + 1}")
            self._configure_client()
            return True
        else:
            logger.error("‚ùå ƒê√£ th·ª≠ h·∫øt t·∫•t c·∫£ c√°c API key c·ªßa Gemini")
            return False

    def _switch_to_next_model(self) -> bool:
        """
        Chuy·ªÉn sang model ti·∫øp theo trong danh s√°ch fallback.
        Reset l·∫°i key index v·ªÅ 0 khi chuy·ªÉn model.
        
        Returns:
            True n·∫øu chuy·ªÉn th√†nh c√¥ng, False n·∫øu ƒë√£ h·∫øt model
        """
        self.current_model_index += 1
        if self.current_model_index < len(self.model_names):
            logger.info(f"üîÑ Chuy·ªÉn sang model d·ª± ph√≤ng: {self.model_names[self.current_model_index]}")
            self.current_key_index = 0  # Reset l·∫°i key v·ªÅ ƒë·∫ßu khi ƒë·ªïi model
            self._configure_client()
            return True
        else:
            logger.error("‚ùå ƒê√£ th·ª≠ h·∫øt t·∫•t c·∫£ c√°c model fallback")
            return False

    def generate_content(
        self, 
        prompt: Union[str, List], 
        return_full_response: bool = False
    ) -> Union[str, GenerateContentResponse]:
        """
        T·∫°o n·ªôi dung v·ªõi t·ª± ƒë·ªông x·ª≠ l√Ω key rotation v√† model fallback.
        
        Th·ª© t·ª± th·ª≠:
        1. Model ch√≠nh v·ªõi t·∫•t c·∫£ c√°c key
        2. Model d·ª± ph√≤ng 1 v·ªõi t·∫•t c·∫£ c√°c key
        3. Model d·ª± ph√≤ng 2 v·ªõi t·∫•t c·∫£ c√°c key
        
        Args:
            prompt: C√≥ th·ªÉ l√† string (text prompt) ho·∫∑c list (cho vision tasks v·ªõi ·∫£nh)
            return_full_response: N·∫øu True, tr·∫£ v·ªÅ response object; n·∫øu False, ch·ªâ tr·∫£ v·ªÅ text
        
        Returns:
            str ho·∫∑c GenerateContentResponse t√πy thu·ªôc v√†o return_full_response
            
        Raises:
            ConnectionError: Khi t·∫•t c·∫£ API key v√† model ƒë·ªÅu th·∫•t b·∫°i
        """
        if not self.model:
            logger.error("Model ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh")
            raise RuntimeError("Model ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh")
        
        # V√≤ng l·∫∑p qua c√°c model
        while self.current_model_index < len(self.model_names):
            # V√≤ng l·∫∑p qua c√°c key c·ªßa model hi·ªán t·∫°i
            while self.current_key_index < len(self.api_keys):
                try:
                    current_model_name = self.model_names[self.current_model_index]
                    logger.debug(f"ƒêang g·ª≠i request v·ªõi Model: {current_model_name}, API Key #{self.current_key_index + 1}")
                    # Th·ª≠ t·∫°o n·ªôi dung v·ªõi key v√† model hi·ªán t·∫°i
                    response = self.model.generate_content(prompt)
                    
                    if return_full_response:
                        logger.info(f"‚úÖ Request th√†nh c√¥ng v·ªõi {current_model_name}, tr·∫£ v·ªÅ full response")
                        return response
                    else:
                        logger.info(f"‚úÖ Request th√†nh c√¥ng v·ªõi {current_model_name}, tr·∫£ v·ªÅ text")
                        return response.text.strip()
                        
                except Exception as e:
                    error_str = str(e).lower()
                    logger.warning(f"‚ö†Ô∏è L·ªói khi g·ªçi API: {e}")
                    
                    # N·∫øu l√† l·ªói quota ho·∫∑c key kh√¥ng h·ª£p l·ªá, chuy·ªÉn sang key ti·∫øp theo
                    if "429" in error_str or "quota" in error_str:
                        logger.warning(f"Key #{self.current_key_index + 1} ƒë√£ h·∫øt quota/rate limit")
                        if not self._switch_to_next_key():
                            # H·∫øt key cho model n√†y, th·ª≠ model ti·∫øp theo
                            logger.warning(f"ƒê√£ h·∫øt key cho model {self.model_names[self.current_model_index]}")
                            break
                    elif "api key not valid" in error_str or "invalid" in error_str:
                        logger.warning(f"Key #{self.current_key_index + 1} kh√¥ng h·ª£p l·ªá")
                        if not self._switch_to_next_key():
                            break
                    elif "404" in error_str or "not found" in error_str:
                        # Model kh√¥ng t·ªìn t·∫°i, chuy·ªÉn sang model ti·∫øp theo lu√¥n
                        logger.error(f"Model {self.model_names[self.current_model_index]} kh√¥ng t·ªìn t·∫°i ho·∫∑c kh√¥ng kh·∫£ d·ª•ng")
                        break
                    else:
                        # N·∫øu l√† l·ªói kh√°c (v√≠ d·ª•: l·ªói n·ªôi dung kh√¥ng an to√†n), n√©m ra ngay
                        logger.error(f"L·ªói kh√¥ng th·ªÉ x·ª≠ l√Ω: {e}")
                        raise e
            
            # ƒê√£ th·ª≠ h·∫øt key cho model n√†y, chuy·ªÉn sang model ti·∫øp theo
            if not self._switch_to_next_model():
                # ƒê√£ h·∫øt model ƒë·ªÉ th·ª≠
                break
        
        # N·∫øu v√≤ng l·∫∑p k·∫øt th√∫c m√† kh√¥ng th√†nh c√¥ng, nghƒ©a l√† ƒë√£ h·∫øt t·∫•t c·∫£ key v√† model
        logger.error("T·∫•t c·∫£ c√°c API key v√† model c·ªßa Gemini ƒë·ªÅu ƒë√£ th·∫•t b·∫°i")
        raise ConnectionError("T·∫•t c·∫£ c√°c API key v√† model c·ªßa Gemini ƒë·ªÅu ƒë√£ th·∫•t b·∫°i.")

    def count_tokens(self, prompt: Union[str, List]) -> int:
        """
        ƒê·∫øm s·ªë l∆∞·ª£ng token trong prompt.
        
        Args:
            prompt: Text ho·∫∑c list ƒë·ªÉ ƒë·∫øm token
            
        Returns:
            S·ªë l∆∞·ª£ng token
            
        Raises:
            RuntimeError: N·∫øu model ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh
        """
        if not self.model:
            logger.error("Model ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh")
            raise RuntimeError("Model ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh")
            
        try:
            token_count = self.model.count_tokens(prompt).total_tokens
            logger.debug(f"Token count: {token_count}")
            return token_count
        except Exception as e:
            logger.error(f"L·ªói khi ƒë·∫øm token: {e}")
            raise