#!/usr/bin/env python3
"""
Test script Ä‘á»ƒ kiá»ƒm tra cáº¥u hÃ¬nh Gemini vá»›i multi-model fallback
"""

from gemini_client import GeminiClient
from config import GEMINI_MODELS
import logging

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_gemini_basic():
    """Test cÆ¡ báº£n: khá»Ÿi táº¡o vÃ  gá»i API"""
    print("\n" + "="*60)
    print("TEST 1: Khá»Ÿi táº¡o GeminiClient")
    print("="*60)
    
    try:
        client = GeminiClient()
        print(f"âœ… Khá»Ÿi táº¡o thÃ nh cÃ´ng vá»›i {len(client.model_names)} model(s):")
        for i, model in enumerate(client.model_names, 1):
            print(f"   {i}. {model}")
        print(f"âœ… CÃ³ {len(client.api_keys)} API key(s) kháº£ dá»¥ng")
        return client
    except Exception as e:
        print(f"âŒ Lá»—i khá»Ÿi táº¡o: {e}")
        return None

def test_text_generation(client):
    """Test sinh vÄƒn báº£n Ä‘Æ¡n giáº£n"""
    print("\n" + "="*60)
    print("TEST 2: Text Generation")
    print("="*60)
    
    if not client:
        print("â­ï¸ Bá» qua test (client khÃ´ng kháº£ dá»¥ng)")
        return
    
    test_prompt = "Viáº¿t 1 cÃ¢u ngáº¯n vá» AI (tiáº¿ng Viá»‡t)"
    
    try:
        print(f"ğŸ“ Prompt: '{test_prompt}'")
        print("â³ Äang gá»­i request...")
        
        response = client.generate_content(test_prompt)
        
        print(f"\nâœ… Pháº£n há»“i thÃ nh cÃ´ng!")
        print(f"ğŸ“„ Ná»™i dung: {response}")
        print(f"ğŸ¯ Model Ä‘Æ°á»£c sá»­ dá»¥ng: {client.model_names[client.current_model_index]}")
        print(f"ğŸ”‘ API Key index: #{client.current_key_index + 1}")
        
        return True
    except Exception as e:
        print(f"âŒ Lá»—i: {e}")
        return False

def test_token_counting(client):
    """Test Ä‘áº¿m token"""
    print("\n" + "="*60)
    print("TEST 3: Token Counting")
    print("="*60)
    
    if not client:
        print("â­ï¸ Bá» qua test (client khÃ´ng kháº£ dá»¥ng)")
        return
    
    test_text = "Hello Gemini! This is a test prompt for counting tokens."
    
    try:
        print(f"ğŸ“ Text: '{test_text}'")
        print("â³ Äang Ä‘áº¿m token...")
        
        token_count = client.count_tokens(test_text)
        
        print(f"âœ… Token count: {token_count}")
        return True
    except Exception as e:
        print(f"âŒ Lá»—i: {e}")
        return False

def test_config():
    """Test cáº¥u hÃ¬nh tá»« config.py"""
    print("\n" + "="*60)
    print("TEST 4: Config Verification")
    print("="*60)
    
    print(f"ğŸ“‹ Models trong config.py:")
    for i, model in enumerate(GEMINI_MODELS, 1):
        print(f"   {i}. {model}")
    
    print(f"\nâœ… Tá»•ng cá»™ng {len(GEMINI_MODELS)} model(s) Ä‘Æ°á»£c cáº¥u hÃ¬nh")

def main():
    """Cháº¡y táº¥t cáº£ tests"""
    print("\n" + "ğŸš€ "*20)
    print(" GEMINI MULTI-MODEL FALLBACK TEST SUITE")
    print("ğŸš€ "*20)
    
    # Test 1: Khá»Ÿi táº¡o
    client = test_gemini_basic()
    
    # Test 2: Text generation
    if client:
        test_text_generation(client)
    
    # Test 3: Token counting
    if client:
        test_token_counting(client)
    
    # Test 4: Config
    test_config()
    
    # Tá»•ng káº¿t
    print("\n" + "="*60)
    print("ğŸ“Š Káº¾T THÃšC TEST SUITE")
    print("="*60)
    print("\nğŸ’¡ LÆ°u Ã½:")
    print("   - Náº¿u test tháº¥t báº¡i, kiá»ƒm tra file .env")
    print("   - Äáº£m báº£o cÃ³ Ã­t nháº¥t 1 API key há»£p lá»‡")
    print("   - Kiá»ƒm tra quota táº¡i https://aistudio.google.com/")
    print("\nğŸ“– Xem thÃªm: GEMINI_MODELS.md vÃ  QUICK_START_GEMINI.md")
    print()

if __name__ == "__main__":
    main()
