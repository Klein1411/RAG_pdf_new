import torch
from sentence_transformers import SentenceTransformer
from read_pdf import extract_pdf_pages
from milvus import get_or_create_collection
from config import PDF_PATH
import os

# --- 1. Cáº¤U HÃŒNH ---
# Chá»n model embedding. 
# 'paraphrase-multilingual-mpnet-base-v2' lÃ  má»™t model máº¡nh, Ä‘a ngÃ´n ngá»¯, há»— trá»£ tá»‘t tiáº¿ng Viá»‡t.
EMBEDDING_MODEL_NAME = 'intfloat/multilingual-e5-large-instruct'
COLLECTION_NAME = "pdf_rag_collection"
# Sá»‘ chiá»u cá»§a vector embedding cho model trÃªn lÃ  1024
EMBEDDING_DIM = 1024

def get_embedding_model():
    """
    Khá»Ÿi táº¡o vÃ  tráº£ vá» model embedding, Æ°u tiÃªn sá»­ dá»¥ng GPU náº¿u cÃ³.
    """
    # Kiá»ƒm tra xem cÃ³ GPU khÃ´ng
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ğŸ¤– Äang táº£i model embedding '{EMBEDDING_MODEL_NAME}' lÃªn '{device}'...")
    
    try:
        model = SentenceTransformer(EMBEDDING_MODEL_NAME, device=device)
        print("   -> âœ… Model Ä‘Ã£ táº£i thÃ nh cÃ´ng!")
        return model
    except Exception as e:
        print(f"   -> âŒ Lá»—i khi táº£i model: {e}")
        print("   -> Vui lÃ²ng Ä‘áº£m báº£o báº¡n Ä‘Ã£ cÃ i Ä‘áº·t thÆ° viá»‡n: pip install sentence-transformers")
        return None

def chunk_text(text: str, chunk_size: int = 500, chunk_overlap: int = 50):
    """
    Chia má»™t Ä‘oáº¡n vÄƒn báº£n dÃ i thÃ nh cÃ¡c Ä‘oáº¡n nhá» hÆ¡n (chunks).
    ÄÃ¢y lÃ  ká»¹ thuáº­t quan trá»ng Ä‘á»ƒ RAG hoáº¡t Ä‘á»™ng hiá»‡u quáº£.
    """
    # TÃ¡ch vÄƒn báº£n thÃ nh cÃ¡c cÃ¢u hoáº·c Ä‘oáº¡n nhá» dá»±a trÃªn dáº¥u xuá»‘ng dÃ²ng
    paragraphs = [p.strip() for p in text.split('\n') if p.strip()]
    chunks = []
    for p in paragraphs:
        # ÄÆ¡n giáº£n lÃ  chia theo tá»«ng Ä‘oáº¡n, cÃ³ thá»ƒ cáº£i tiáº¿n thÃªm sau
        chunks.append(p)
    return chunks


def populate_database():
    """
    HÃ m chÃ­nh: Äá»c PDF, táº¡o embedding, vÃ  lÆ°u vÃ o Milvus.
    """
    print("--- Báº®T Äáº¦U QUÃ TRÃŒNH Äá»’NG Bá»˜ Dá»® LIá»†U VÃ€O MILVUS ---")
    
    # --- BÆ°á»›c 1: Khá»Ÿi táº¡o cÃ¡c thÃ nh pháº§n cáº§n thiáº¿t ---
    model = get_embedding_model()
    if not model:
        return

    # Láº¥y hoáº·c táº¡o má»›i collection, xÃ³a cÃ¡i cÅ© Ä‘i Ä‘á»ƒ lÃ m má»›i
    print("\n--- BÆ°á»›c 2: Chuáº©n bá»‹ collection trÃªn Milvus ---")
    collection = get_or_create_collection(COLLECTION_NAME, dim=EMBEDDING_DIM, recreate=True)

    # --- BÆ°á»›c 3: Äá»c vÃ  xá»­ lÃ½ file PDF ---
    print(f"\n--- BÆ°á»›c 3: Äá»c vÃ  xá»­ lÃ½ file PDF: {PDF_PATH} ---")
    if not os.path.exists(PDF_PATH):
        print(f"âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y file PDF táº¡i '{PDF_PATH}'.")
        return
        
    pages_data = extract_pdf_pages(PDF_PATH)
    if not pages_data:
        print("âŒ KhÃ´ng thá»ƒ trÃ­ch xuáº¥t dá»¯ liá»‡u tá»« PDF.")
        return

    # --- BÆ°á»›c 4: Chuáº©n bá»‹ vÄƒn báº£n vÃ  báº£ng Ä‘á»ƒ embedding ---
    print("\n--- BÆ°á»›c 4: Chuáº©n bá»‹ vÄƒn báº£n vÃ  báº£ng (chunking) ---")
    all_chunks = []
    metadata = []
    for page in pages_data:
        page_num = page['page_number']
        
        # Xá»­ lÃ½ pháº§n vÄƒn báº£n (text)
        if page.get('text'):
            # Chá»‰ xá»­ lÃ½ cÃ¡c trang cÃ³ ná»™i dung vÃ  khÃ´ng pháº£i lÃ  áº£nh scan (Ä‘Ã£ cÃ³ text)
            if page['source'] in ['gemini', 'manual']:
                page_text = page['text']
                chunks = chunk_text(page_text)
                for chunk in chunks:
                    all_chunks.append(chunk)
                    metadata.append({
                        "pdf_source": os.path.basename(PDF_PATH),
                        "page": page_num
                    })

        # Xá»­ lÃ½ pháº§n báº£ng (tables)
        if page.get('tables'):
            for table_num, table_data in enumerate(page['tables'], 1):
                # Chuyá»ƒn báº£ng thÃ nh má»™t chuá»—i vÄƒn báº£n Ä‘á»ƒ embedding
                # CÃ¡ch Ä‘Æ¡n giáº£n lÃ  ná»‘i cÃ¡c hÃ ng vÃ  cá»™t láº¡i vá»›i nhau
                try:
                    table_string = f"Ná»™i dung cá»§a báº£ng {table_num} trÃªn trang {page_num}:\n"
                    table_string += "\n".join([" | ".join(map(str, row)) for row in table_data])
                    
                    all_chunks.append(table_string)
                    metadata.append({
                        "pdf_source": os.path.basename(PDF_PATH),
                        "page": page_num
                    })
                    print(f"   -> ÄÃ£ xá»­ lÃ½ Báº£ng {table_num} trÃªn trang {page_num}.")
                except Exception as e:
                    print(f"   -> âš ï¸ Lá»—i khi xá»­ lÃ½ báº£ng {table_num} trang {page_num}: {e}")

    if not all_chunks:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y Ä‘oáº¡n vÄƒn báº£n hoáº·c báº£ng nÃ o Ä‘á»ƒ xá»­ lÃ½.")
        return
        
    print(f"   -> Tá»•ng cá»™ng cÃ³ {len(all_chunks)} Ä‘oáº¡n vÄƒn báº£n vÃ  báº£ng cáº§n xá»­ lÃ½.")

    # --- BÆ°á»›c 5: Táº¡o embedding cho táº¥t cáº£ cÃ¡c chunks ---
    print("\n--- BÆ°á»›c 5: Táº¡o embeddings cho cÃ¡c Ä‘oáº¡n vÄƒn báº£n vÃ  báº£ng ---")
    embeddings = model.encode(all_chunks, show_progress_bar=True)
    print("   -> âœ… Táº¡o embedding hoÃ n táº¥t.")

    # --- BÆ°á»›c 6: Chuáº©n bá»‹ vÃ  lÆ°u dá»¯ liá»‡u vÃ o Milvus ---
    print("\n--- BÆ°á»›c 6: LÆ°u dá»¯ liá»‡u vÃ o Milvus ---")
    entities = [
        embeddings,                                 # Field: embedding
        all_chunks,                                 # Field: text
        [meta['pdf_source'] for meta in metadata],  # Field: pdf_source
        [meta['page'] for meta in metadata]         # Field: page
    ]
    
    try:
        insert_result = collection.insert(entities)
        print(f"   -> âœ… ChÃ¨n thÃ nh cÃ´ng {insert_result.insert_count} vectors vÃ o Milvus.")
        
        # Flush collection Ä‘á»ƒ Ä‘áº£m báº£o dá»¯ liá»‡u Ä‘Æ°á»£c ghi xuá»‘ng Ä‘Ä©a
        print("   -> Äang flush collection...")
        collection.flush()
        print("   -> âœ… Flush hoÃ n táº¥t.")

    except Exception as e:
        print(f"   -> âŒ Lá»—i khi chÃ¨n dá»¯ liá»‡u vÃ o Milvus: {e}")

    print("\n--- QUÃ TRÃŒNH Äá»’NG Bá»˜ HOÃ€N Táº¤T ---")


if __name__ == "__main__":
    populate_database()