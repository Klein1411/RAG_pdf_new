import os
import dotenv
import google.generativeai as genai

class GeminiClient:
    """
    M·ªôt tr√¨nh qu·∫£n l√Ω stateful cho API c·ªßa Google Gemini.

    Class n√†y s·∫Ω qu·∫£n l√Ω m·ªôt danh s√°ch c√°c API key v√† t·ª± ƒë·ªông xoay v√≤ng
    qua c√°c key khi g·∫∑p l·ªói c√≥ th·ªÉ th·ª≠ l·∫°i (v√≠ d·ª•: l·ªói quota).
    """
    def __init__(self, model_name: str = "gemini-2.5-flash"):
        dotenv.load_dotenv()
        self.api_keys = [key for key in [os.getenv(f"GEMINI_API_KEY_{i}") for i in range(1, 10)] if key]
        if not self.api_keys:
            raise ValueError("Kh√¥ng t√¨m th·∫•y bi·∫øn m√¥i tr∆∞·ªùng GEMINI_API_KEY n√†o trong file .env")

        self.current_key_index = 0
        self.model_name = model_name # S·ª≠ d·ª•ng model_name ƒë∆∞·ª£c truy·ªÅn v√†o
        self._configure_client()

    def _configure_client(self):
        """C·∫•u h√¨nh client genai v·ªõi key hi·ªán t·∫°i."""
        if self.current_key_index >= len(self.api_keys):
            return False # ƒê√£ h·∫øt key ƒë·ªÉ th·ª≠
        
        current_key = self.api_keys[self.current_key_index]
        print(f"üîë ƒêang c·∫•u h√¨nh Gemini v·ªõi API Key #{self.current_key_index + 1}")
        genai.configure(api_key=current_key)
        self.model = genai.GenerativeModel(self.model_name)
        return True

    def _switch_to_next_key(self) -> bool:
        """
        Chuy·ªÉn sang API key ti·∫øp theo v√† c·∫•u h√¨nh l·∫°i client.
        Tr·∫£ v·ªÅ True n·∫øu chuy·ªÉn th√†nh c√¥ng, False n·∫øu ƒë√£ h·∫øt key.
        """
        self.current_key_index += 1
        if self.current_key_index < len(self.api_keys):
            self._configure_client()
            return True
        else:
            print("   -> ‚ùå ƒê√£ th·ª≠ h·∫øt t·∫•t c·∫£ c√°c API key c·ªßa Gemini.")
            return False

    def generate_content(self, prompt, return_full_response: bool = False):
        """
        T·∫°o n·ªôi dung v√† t·ª± ƒë·ªông x·ª≠ l√Ω vi·ªác xoay v√≤ng key khi g·∫∑p l·ªói.
        
        Args:
            prompt: C√≥ th·ªÉ l√† string (text prompt) ho·∫∑c list (cho vision tasks v·ªõi ·∫£nh)
            return_full_response: N·∫øu True, tr·∫£ v·ªÅ response object; n·∫øu False, ch·ªâ tr·∫£ v·ªÅ text
        
        Returns:
            str ho·∫∑c response object t√πy thu·ªôc v√†o return_full_response
        """
        while self.current_key_index < len(self.api_keys):
            try:
                # Th·ª≠ t·∫°o n·ªôi dung v·ªõi key hi·ªán t·∫°i
                response = self.model.generate_content(prompt)
                
                if return_full_response:
                    return response
                else:
                    return response.text.strip()
                    
            except Exception as e:
                error_str = str(e).lower()
                # N·∫øu l√† l·ªói quota ho·∫∑c key kh√¥ng h·ª£p l·ªá, chuy·ªÉn sang key ti·∫øp theo
                if "429" in error_str and "quota" in error_str:
                    print(f"   -> ‚ö†Ô∏è Key #{self.current_key_index + 1} ƒë√£ h·∫øt quota. ƒêang chuy·ªÉn key...")
                    if not self._switch_to_next_key():
                        # N·∫øu kh√¥ng c√≤n key n√†o, n√©m ra l·ªói cu·ªëi c√πng
                        raise ConnectionError("T·∫•t c·∫£ c√°c API key c·ªßa Gemini ƒë·ªÅu ƒë√£ h·∫øt quota.")
                elif "api key not valid" in error_str:
                    print(f"   -> ‚ö†Ô∏è Key #{self.current_key_index + 1} kh√¥ng h·ª£p l·ªá. ƒêang chuy·ªÉn key...")
                    if not self._switch_to_next_key():
                        raise ConnectionError("T·∫•t c·∫£ c√°c API key c·ªßa Gemini ƒë·ªÅu kh√¥ng h·ª£p l·ªá.")
                else:
                    # N·∫øu l√† l·ªói kh√°c (v√≠ d·ª•: l·ªói n·ªôi dung kh√¥ng an to√†n), n√©m ra ngay
                    raise e
        
        # N·∫øu v√≤ng l·∫∑p k·∫øt th√∫c m√† kh√¥ng th√†nh c√¥ng, nghƒ©a l√† ƒë√£ h·∫øt key
        raise ConnectionError("T·∫•t c·∫£ c√°c API key c·ªßa Gemini ƒë·ªÅu ƒë√£ ƒë∆∞·ª£c th·ª≠ v√† th·∫•t b·∫°i.")

    def count_tokens(self, prompt: str):
        """Wrapper cho h√†m count_tokens c·ªßa model hi·ªán t·∫°i."""
        return self.model.count_tokens(prompt)